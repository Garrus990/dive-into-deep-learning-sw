{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ded31713",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# Predicting House Prices on Kaggle\n",
    ":label:`sec_kaggle_house`\n",
    "\n",
    "Now that we have introduced some basic tools\n",
    "for building and training deep networks\n",
    "and regularizing them with techniques including\n",
    "weight decay and dropout,\n",
    "we are ready to put all this knowledge into practice\n",
    "by participating in a Kaggle competition.\n",
    "The house price prediction competition\n",
    "is a great place to start.\n",
    "The data is fairly generic and do not exhibit exotic structure\n",
    "that might require specialized models (as audio or video might).\n",
    "This dataset, collected by Bart de Cock in 2011 :cite:`De-Cock.2011`,\n",
    "covers house prices in Ames, IA from the period of 2006--2010.\n",
    "It is considerably larger than the famous [Boston housing dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names) of Harrison and Rubinfeld (1978),\n",
    "boasting both more examples and more features.\n",
    "\n",
    "\n",
    "In this section, we will walk you through details of\n",
    "data preprocessing, model design, and hyperparameter selection.\n",
    "We hope that through a hands-on approach,\n",
    "you will gain some intuitions that will guide you\n",
    "in your career as a data scientist.\n",
    "\n",
    "\n",
    "## Downloading Data\n",
    "\n",
    "Throughout the book, we will train and test models\n",
    "on various downloaded datasets.\n",
    "Here, we (**implement two utility functions**)\n",
    "to download files and extract zip or tar files.\n",
    "Again, we defer their implementations into :numref:`sec_utils`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71363328",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T05:44:45.649695Z",
     "iopub.status.busy": "2022-12-14T05:44:45.648953Z",
     "iopub.status.idle": "2022-12-14T05:44:45.660642Z",
     "shell.execute_reply": "2022-12-14T05:44:45.659785Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def download(url, folder, sha1_hash=None):\n",
    "    \"\"\"Download a file to folder and return the local filepath.\"\"\"\n",
    "\n",
    "def extract(filename, folder):\n",
    "    \"\"\"Extract a zip/tar file into folder.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a541fd3d",
   "metadata": {
    "origin_pos": 3
   },
   "source": [
    "## Kaggle\n",
    "\n",
    "[Kaggle](https://www.kaggle.com) is a popular platform\n",
    "that hosts machine learning competitions.\n",
    "Each competition centers on a dataset and many\n",
    "are sponsored by stakeholders who offer prizes\n",
    "to the winning solutions.\n",
    "The platform helps users to interact\n",
    "via forums and shared code,\n",
    "fostering both collaboration and competition.\n",
    "While leaderboard chasing often spirals out of control,\n",
    "with researchers focusing myopically on preprocessing steps\n",
    "rather than asking fundamental questions,\n",
    "there is also tremendous value in the objectivity of a platform\n",
    "that facilitates direct quantitative comparisons\n",
    "among competing approaches as well as code sharing\n",
    "so that everyone can learn what did and did not work.\n",
    "If you want to participate in a Kaggle competition,\n",
    "you will first need to register for an account\n",
    "(see :numref:`fig_kaggle`).\n",
    "\n",
    "![The Kaggle website.](../img/kaggle.png)\n",
    ":width:`400px`\n",
    ":label:`fig_kaggle`\n",
    "\n",
    "On the house price prediction competition page, as illustrated\n",
    "in :numref:`fig_house_pricing`,\n",
    "you can find the dataset (under the \"Data\" tab),\n",
    "submit predictions, and see your ranking,\n",
    "The URL is right here:\n",
    "\n",
    "> https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "\n",
    "![The house price prediction competition page.](../img/house-pricing.png)\n",
    ":width:`400px`\n",
    ":label:`fig_house_pricing`\n",
    "\n",
    "## Accessing and Reading the Dataset\n",
    "\n",
    "Note that the competition data is separated\n",
    "into training and test sets.\n",
    "Each record includes the property value of the house\n",
    "and attributes such as street type, year of construction,\n",
    "roof type, basement condition, etc.\n",
    "The features consist of various data types.\n",
    "For example, the year of construction\n",
    "is represented by an integer,\n",
    "the roof type by discrete categorical assignments,\n",
    "and other features by floating point numbers.\n",
    "And here is where reality complicates things:\n",
    "for some examples, some data is altogether missing\n",
    "with the missing value marked simply as \"na\".\n",
    "The price of each house is included\n",
    "for the training set only\n",
    "(it is a competition after all).\n",
    "We will want to partition the training set\n",
    "to create a validation set,\n",
    "but we only get to evaluate our models on the official test set\n",
    "after uploading predictions to Kaggle.\n",
    "The \"Data\" tab on the competition tab\n",
    "in :numref:`fig_house_pricing`\n",
    "has links to download the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b502cb",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T05:44:45.665309Z",
     "iopub.status.busy": "2022-12-14T05:44:45.664566Z",
     "iopub.status.idle": "2022-12-14T05:44:47.978963Z",
     "shell.execute_reply": "2022-12-14T05:44:47.978065Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f3226",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "To get started, we will [**read in and process the data\n",
    "using `pandas`**], which we have introduced in :numref:`sec_pandas`.\n",
    "For convenience, we can download and cache\n",
    "the Kaggle housing dataset.\n",
    "If a file corresponding to this dataset already exists in the cache directory and its SHA-1 matches `sha1_hash`, our code will use the cached file to avoid clogging up your internet with redundant downloads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9342dc",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "30"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T05:44:47.983887Z",
     "iopub.status.busy": "2022-12-14T05:44:47.983518Z",
     "iopub.status.idle": "2022-12-14T05:44:47.990002Z",
     "shell.execute_reply": "2022-12-14T05:44:47.989027Z"
    },
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class KaggleHouse(d2l.DataModule):\n",
    "    def __init__(self, batch_size, train=None, val=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if self.train is None:\n",
    "            self.raw_train = pd.read_csv(d2l.download(\n",
    "                d2l.DATA_URL + 'kaggle_house_pred_train.csv', self.root,\n",
    "                sha1_hash='585e9cc93e70b39160e7921475f9bcd7d31219ce'))\n",
    "            self.raw_val = pd.read_csv(d2l.download(\n",
    "                d2l.DATA_URL + 'kaggle_house_pred_test.csv', self.root,\n",
    "                sha1_hash='fa19780a7b011d9b009e8bff8e99922a8ee2eb90'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99b158",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "The training dataset includes 1460 examples,\n",
    "80 features, and 1 label, while the validation data\n",
    "contains 1459 examples and 80 features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4aad30d",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "31"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T05:44:47.994197Z",
     "iopub.status.busy": "2022-12-14T05:44:47.993914Z",
     "iopub.status.idle": "2022-12-14T05:44:48.351280Z",
     "shell.execute_reply": "2022-12-14T05:44:48.350454Z"
    },
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data/kaggle_house_pred_train.csv from http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csv...\n",
      "Downloading ../data/kaggle_house_pred_test.csv from http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csv...\n",
      "(1460, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "data = KaggleHouse(batch_size=64)\n",
    "print(data.raw_train.shape)\n",
    "print(data.raw_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58a385f",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Let's [**take a look at the first four and last two features\n",
    "as well as the label (SalePrice)**] from the first four examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b0cc3e",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T05:44:48.355678Z",
     "iopub.status.busy": "2022-12-14T05:44:48.355390Z",
     "iopub.status.idle": "2022-12-14T05:44:48.364527Z",
     "shell.execute_reply": "2022-12-14T05:44:48.363766Z"
    },
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
      "0   1          60       RL         65.0       WD        Normal     208500\n",
      "1   2          20       RL         80.0       WD        Normal     181500\n",
      "2   3          60       RL         68.0       WD        Normal     223500\n",
      "3   4          70       RL         60.0       WD       Abnorml     140000\n"
     ]
    }
   ],
   "source": [
    "print(data.raw_train.iloc[:4, [0, 1, 2, 3, -3, -2, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b8cea",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "We can see that in each example, the first feature is the ID.\n",
    "This helps the model identify each training example.\n",
    "While this is convenient, it does not carry\n",
    "any information for prediction purposes.\n",
    "Hence, we will remove it from the dataset\n",
    "before feeding the data into the model.\n",
    "Besides, given a wide variety of data types,\n",
    "we will need to preprocess the data before we can start modeling.\n",
    "\n",
    "\n",
    "Let's start with the numerical features.\n",
    "First, we apply a heuristic,\n",
    "[**replacing all missing values\n",
    "by the corresponding feature's mean.**]\n",
    "Then, to put all features on a common scale,\n",
    "we (***standardize* the data by\n",
    "rescaling features to zero mean and unit variance**):\n",
    "\n",
    "$$x \\leftarrow \\frac{x - \\mu}{\\sigma},$$\n",
    "\n",
    "where $\\mu$ and $\\sigma$ denote mean and standard deviation, respectively.\n",
    "To verify that this indeed transforms\n",
    "our feature (variable) such that it has zero mean and unit variance,\n",
    "note that $E[\\frac{x-\\mu}{\\sigma}] = \\frac{\\mu - \\mu}{\\sigma} = 0$\n",
    "and that $E[(x-\\mu)^2] = (\\sigma^2 + \\mu^2) - 2\\mu^2+\\mu^2 = \\sigma^2$.\n",
    "Intuitively, we standardize the data\n",
    "for two reasons.\n",
    "First, it proves convenient for optimization.\n",
    "Second, because we do not know *a priori*\n",
    "which features will be relevant,\n",
    "we do not want to penalize coefficients\n",
    "assigned to one feature more than on any other.\n",
    "\n",
    "[**Next we deal with discrete values.**]\n",
    "This includes features such as \"MSZoning\".\n",
    "(**We replace them by a one-hot encoding**)\n",
    "in the same way that we previously transformed\n",
    "multiclass labels into vectors (see :numref:`subsec_classification-problem`).\n",
    "For instance, \"MSZoning\" assumes the values \"RL\" and \"RM\".\n",
    "Dropping the \"MSZoning\" feature,\n",
    "two new indicator features\n",
    "\"MSZoning_RL\" and \"MSZoning_RM\" are created with values being either 0 or 1.\n",
    "According to one-hot encoding,\n",
    "if the original value of \"MSZoning\" is \"RL\",\n",
    "then \"MSZoning_RL\" is 1 and \"MSZoning_RM\" is 0.\n",
    "The `pandas` package does this automatically for us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "caa8b8e7",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "32"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T05:44:48.369374Z",
     "iopub.status.busy": "2022-12-14T05:44:48.369089Z",
     "iopub.status.idle": "2022-12-14T05:44:48.375425Z",
     "shell.execute_reply": "2022-12-14T05:44:48.374661Z"
    },
    "origin_pos": 15,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "@d2l.add_to_class(KaggleHouse)\n",
    "def preprocess(self, standardize=True):\n",
    "    # Remove the ID and label columns\n",
    "    label = 'SalePrice'\n",
    "    features = pd.concat(\n",
    "        (self.raw_train.drop(columns=['Id', label]),\n",
    "         self.raw_val.drop(columns=['Id'])))\n",
    "    # Standardize numerical columns\n",
    "    numeric_features = features.dtypes[features.dtypes != 'object'].index\n",
    "    if standardize:\n",
    "        features[numeric_features] = features[numeric_features].apply(\n",
    "            lambda x: (x - x.mean()) / (x.std()))\n",
    "    # Replace NAN numerical features by 0\n",
    "    numeric_features_means = features[numeric_features].mean(axis=0)\n",
    "    features[numeric_features] = features[numeric_features].fillna(numeric_features_means.to_dict())\n",
    "    # Replace discrete features by one-hot encoding.\n",
    "    features = pd.get_dummies(features, dummy_na=True)\n",
    "    # Save preprocessed features\n",
    "    self.train = features[:self.raw_train.shape[0]].copy()\n",
    "    self.train[label] = self.raw_train[label]\n",
    "    self.val = features[self.raw_train.shape[0]:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4006277",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "You can see that this conversion increases\n",
    "the number of features from 79 to 331 (excluding ID and label columns).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e1209bc",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "33"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T05:44:48.379449Z",
     "iopub.status.busy": "2022-12-14T05:44:48.379166Z",
     "iopub.status.idle": "2022-12-14T05:44:48.488831Z",
     "shell.execute_reply": "2022-12-14T05:44:48.488050Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 332)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.preprocess(standardize=False)\n",
    "data.train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c070c",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "## Error Measure\n",
    "\n",
    "To get started we will train a linear model with squared loss. Not surprisingly, our linear model will not lead to a competition-winning submission but it provides a sanity check to see whether there is meaningful information in the data. If we cannot do better than random guessing here, then there might be a good chance that we have a data processing bug. And if things work, the linear model will serve as a baseline giving us some intuition about how close the simple model gets to the best reported models, giving us a sense of how much gain we should expect from fancier models.\n",
    "\n",
    "With house prices, as with stock prices,\n",
    "we care about relative quantities\n",
    "more than absolute quantities.\n",
    "Thus [**we tend to care more about\n",
    "the relative error $\\frac{y - \\hat{y}}{y}$**]\n",
    "than about the absolute error $y - \\hat{y}$.\n",
    "For instance, if our prediction is off by USD 100,000\n",
    "when estimating the price of a house in Rural Ohio,\n",
    "where the value of a typical house is 125,000 USD,\n",
    "then we are probably doing a horrible job.\n",
    "On the other hand, if we err by this amount\n",
    "in Los Altos Hills, California,\n",
    "this might represent a stunningly accurate prediction\n",
    "(there, the median house price exceeds 4 million USD).\n",
    "\n",
    "(**One way to address this problem is to\n",
    "measure the discrepancy in the logarithm of the price estimates.**)\n",
    "In fact, this is also the official error measure\n",
    "used by the competition to evaluate the quality of submissions.\n",
    "After all, a small value $\\delta$ for $|\\log y - \\log \\hat{y}| \\leq \\delta$\n",
    "translates into $e^{-\\delta} \\leq \\frac{\\hat{y}}{y} \\leq e^\\delta$.\n",
    "This leads to the following root-mean-squared-error between the logarithm of the predicted price and the logarithm of the label price:\n",
    "\n",
    "$$\\sqrt{\\frac{1}{n}\\sum_{i=1}^n\\left(\\log y_i -\\log \\hat{y}_i\\right)^2}.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31a170d0",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "60"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T05:44:48.493643Z",
     "iopub.status.busy": "2022-12-14T05:44:48.493357Z",
     "iopub.status.idle": "2022-12-14T05:44:48.498629Z",
     "shell.execute_reply": "2022-12-14T05:44:48.497885Z"
    },
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "@d2l.add_to_class(KaggleHouse)\n",
    "def get_dataloader(self, train):\n",
    "    label = 'SalePrice'\n",
    "    data = self.train if train else self.val\n",
    "    if label not in data: return\n",
    "    get_tensor = lambda x: torch.tensor(x.values, dtype=torch.float32)\n",
    "    # Logarithm of prices\n",
    "    tensors = (get_tensor(data.drop(columns=[label])),  # X\n",
    "               torch.log(get_tensor(data[label])).reshape((-1, 1)))  # Y\n",
    "    return self.get_tensorloader(tensors, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf1fea",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## $K$-Fold Cross-Validation\n",
    "\n",
    "You might recall that we introduced [**cross-validation**]\n",
    "in :numref:`subsec_generalization-model-selection`, where we discussed how to deal\n",
    "with model selection.\n",
    "We will put this to good use to select the model design\n",
    "and to adjust the hyperparameters.\n",
    "We first need a function that returns\n",
    "the $i^\\mathrm{th}$ fold of the data\n",
    "in a $K$-fold cross-validation procedure.\n",
    "It proceeds by slicing out the $i^\\mathrm{th}$ segment\n",
    "as validation data and returning the rest as training data.\n",
    "Note that this is not the most efficient way of handling data\n",
    "and we would definitely do something much smarter\n",
    "if our dataset was considerably larger.\n",
    "But this added complexity might obfuscate our code unnecessarily\n",
    "so we can safely omit it here owing to the simplicity of our problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d37ac3ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T05:44:48.502724Z",
     "iopub.status.busy": "2022-12-14T05:44:48.502411Z",
     "iopub.status.idle": "2022-12-14T05:44:48.507204Z",
     "shell.execute_reply": "2022-12-14T05:44:48.506405Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def k_fold_data(data, k):\n",
    "    rets = []\n",
    "    fold_size = data.train.shape[0] // k\n",
    "    for j in range(k):\n",
    "        idx = range(j * fold_size, (j+1) * fold_size)\n",
    "        rets.append(KaggleHouse(data.batch_size, data.train.drop(index=idx),\n",
    "                                data.train.loc[idx]))\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b9241",
   "metadata": {
    "origin_pos": 22
   },
   "source": [
    "[**The average validation error is returned**]\n",
    "when we train $K$ times in the $K$-fold cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "648caf70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T05:44:48.511527Z",
     "iopub.status.busy": "2022-12-14T05:44:48.511267Z",
     "iopub.status.idle": "2022-12-14T05:44:48.516239Z",
     "shell.execute_reply": "2022-12-14T05:44:48.515476Z"
    },
    "origin_pos": 23,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def k_fold(trainer, data, k, lr):\n",
    "    val_loss, models = [], []\n",
    "    for i, data_fold in enumerate(k_fold_data(data, k)):\n",
    "        # print(data_fold.train[\"SalePrice\"].head())\n",
    "        model = d2l.LinearRegression(lr)\n",
    "        model.board.yscale='log'\n",
    "        if i != 0: model.board.display = False\n",
    "        trainer.fit(model, data_fold)\n",
    "        print(float(model.board.data['val_loss'][-1].y))\n",
    "        val_loss.append(float(model.board.data['val_loss'][-1].y))\n",
    "        models.append(model)\n",
    "    print(f'average validation log mse = {sum(val_loss)/len(val_loss)}')\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab51058",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "## [**Model Selection**]\n",
    "\n",
    "In this example, we pick an untuned set of hyperparameters\n",
    "and leave it up to the reader to improve the model.\n",
    "Finding a good choice can take time,\n",
    "depending on how many variables one optimizes over.\n",
    "With a large enough dataset,\n",
    "and the normal sorts of hyperparameters,\n",
    "$K$-fold cross-validation tends to be\n",
    "reasonably resilient against multiple testing.\n",
    "However, if we try an unreasonably large number of options\n",
    "we might just get lucky and find that our validation\n",
    "performance is no longer representative of the true error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "780ad65c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T05:44:48.520362Z",
     "iopub.status.busy": "2022-12-14T05:44:48.520082Z",
     "iopub.status.idle": "2022-12-14T05:44:57.541057Z",
     "shell.execute_reply": "2022-12-14T05:44:57.540241Z"
    },
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "average validation log mse = nan\n",
      "Error in callback <function _draw_all_if_interactive at 0x7f558336f640> (for post_execute):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data has no positive values, and therefore can not be log-scaled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/pyplot.py:119\u001b[0m, in \u001b[0;36m_draw_all_if_interactive\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_draw_all_if_interactive\u001b[39m():\n\u001b[1;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m matplotlib\u001b[39m.\u001b[39mis_interactive():\n\u001b[0;32m--> 119\u001b[0m         draw_all()\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/_pylab_helpers.py:132\u001b[0m, in \u001b[0;36mGcf.draw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mfor\u001b[39;00m manager \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m    131\u001b[0m     \u001b[39mif\u001b[39;00m force \u001b[39mor\u001b[39;00m manager\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mstale:\n\u001b[0;32m--> 132\u001b[0m         manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mdraw_idle()\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/backend_bases.py:2054\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_idle_drawing:\n\u001b[1;32m   2053\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_idle_draw_cntx():\n\u001b[0;32m-> 2054\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdraw(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:405\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m RendererAgg\u001b[39m.\u001b[39mlock, \\\n\u001b[1;32m    403\u001b[0m      (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\u001b[39m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\n\u001b[1;32m    404\u001b[0m       \u001b[39melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 405\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrenderer)\n\u001b[1;32m    406\u001b[0m     \u001b[39m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    407\u001b[0m     \u001b[39m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdraw()\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/artist.py:74\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 74\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     76\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/figure.py:3082\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3079\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3081\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3082\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3083\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3085\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   3086\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/axes/_base.py:3100\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3097\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m   3098\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[0;32m-> 3100\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3101\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3103\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/axis.py:1304\u001b[0m, in \u001b[0;36mAxis.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m renderer\u001b[39m.\u001b[39mopen_group(\u001b[39m__name__\u001b[39m, gid\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_gid())\n\u001b[0;32m-> 1304\u001b[0m ticks_to_draw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_ticks()\n\u001b[1;32m   1305\u001b[0m tlb1, tlb2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[1;32m   1307\u001b[0m \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks_to_draw:\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/axis.py:1190\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_ticks\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1186\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m    Update ticks (position and labels) using the current data interval of\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39m    the axes.  Return the list of ticks that will be drawn.\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m     major_locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_majorticklocs()\n\u001b[1;32m   1191\u001b[0m     major_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmajor\u001b[39m.\u001b[39mformatter\u001b[39m.\u001b[39mformat_ticks(major_locs)\n\u001b[1;32m   1192\u001b[0m     major_ticks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_major_ticks(\u001b[39mlen\u001b[39m(major_locs))\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/axis.py:1416\u001b[0m, in \u001b[0;36mAxis.get_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_majorticklocs\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1415\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return this Axis' major tick locations in data coordinates.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1416\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmajor\u001b[39m.\u001b[39;49mlocator()\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/ticker.py:2346\u001b[0m, in \u001b[0;36mLogLocator.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the locations of the ticks.\"\"\"\u001b[39;00m\n\u001b[1;32m   2345\u001b[0m vmin, vmax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis\u001b[39m.\u001b[39mget_view_interval()\n\u001b[0;32m-> 2346\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtick_values(vmin, vmax)\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/ticker.py:2371\u001b[0m, in \u001b[0;36mLogLocator.tick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2368\u001b[0m         vmin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis\u001b[39m.\u001b[39mget_minpos()\n\u001b[1;32m   2370\u001b[0m     \u001b[39mif\u001b[39;00m vmin \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(vmin):\n\u001b[0;32m-> 2371\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2372\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mData has no positive values, and therefore can not be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2373\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mlog-scaled.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2375\u001b[0m _log\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39mvmin \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vmax \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, vmin, vmax)\n\u001b[1;32m   2377\u001b[0m \u001b[39mif\u001b[39;00m vmax \u001b[39m<\u001b[39m vmin:\n",
      "\u001b[0;31mValueError\u001b[0m: Data has no positive values, and therefore can not be log-scaled."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data has no positive values, and therefore can not be log-scaled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/IPython/core/formatters.py:338\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    339\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    340\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/backend_bases.py:2314\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2308\u001b[0m     renderer \u001b[39m=\u001b[39m _get_renderer(\n\u001b[1;32m   2309\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure,\n\u001b[1;32m   2310\u001b[0m         functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m   2311\u001b[0m             print_method, orientation\u001b[39m=\u001b[39morientation)\n\u001b[1;32m   2312\u001b[0m     )\n\u001b[1;32m   2313\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mgetattr\u001b[39m(renderer, \u001b[39m\"\u001b[39m\u001b[39m_draw_disabled\u001b[39m\u001b[39m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2314\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m   2316\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2317\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/artist.py:74\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 74\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     76\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/figure.py:3082\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3079\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3081\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3082\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3083\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3085\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   3086\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/axes/_base.py:3100\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3097\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m   3098\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[0;32m-> 3100\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3101\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3103\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/axis.py:1304\u001b[0m, in \u001b[0;36mAxis.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m renderer\u001b[39m.\u001b[39mopen_group(\u001b[39m__name__\u001b[39m, gid\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_gid())\n\u001b[0;32m-> 1304\u001b[0m ticks_to_draw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_ticks()\n\u001b[1;32m   1305\u001b[0m tlb1, tlb2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[1;32m   1307\u001b[0m \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks_to_draw:\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/axis.py:1190\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_ticks\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1186\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m    Update ticks (position and labels) using the current data interval of\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39m    the axes.  Return the list of ticks that will be drawn.\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m     major_locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_majorticklocs()\n\u001b[1;32m   1191\u001b[0m     major_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmajor\u001b[39m.\u001b[39mformatter\u001b[39m.\u001b[39mformat_ticks(major_locs)\n\u001b[1;32m   1192\u001b[0m     major_ticks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_major_ticks(\u001b[39mlen\u001b[39m(major_locs))\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/axis.py:1416\u001b[0m, in \u001b[0;36mAxis.get_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_majorticklocs\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1415\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return this Axis' major tick locations in data coordinates.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1416\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmajor\u001b[39m.\u001b[39;49mlocator()\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/ticker.py:2346\u001b[0m, in \u001b[0;36mLogLocator.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the locations of the ticks.\"\"\"\u001b[39;00m\n\u001b[1;32m   2345\u001b[0m vmin, vmax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis\u001b[39m.\u001b[39mget_view_interval()\n\u001b[0;32m-> 2346\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtick_values(vmin, vmax)\n",
      "File \u001b[0;32m~/PythonProjects/dive-into-deep-learning/.venv/lib/python3.10/site-packages/matplotlib/ticker.py:2371\u001b[0m, in \u001b[0;36mLogLocator.tick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2368\u001b[0m         vmin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis\u001b[39m.\u001b[39mget_minpos()\n\u001b[1;32m   2370\u001b[0m     \u001b[39mif\u001b[39;00m vmin \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(vmin):\n\u001b[0;32m-> 2371\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2372\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mData has no positive values, and therefore can not be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2373\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mlog-scaled.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2375\u001b[0m _log\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39mvmin \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vmax \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, vmin, vmax)\n\u001b[1;32m   2377\u001b[0m \u001b[39mif\u001b[39;00m vmax \u001b[39m<\u001b[39m vmin:\n",
      "\u001b[0;31mValueError\u001b[0m: Data has no positive values, and therefore can not be log-scaled."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = d2l.Trainer(max_epochs=10)\n",
    "models = k_fold(trainer, data, k=5, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c52e3c",
   "metadata": {
    "origin_pos": 26
   },
   "source": [
    "Notice that sometimes the number of training errors\n",
    "for a set of hyperparameters can be very low,\n",
    "even as the number of errors on $K$-fold cross-validation\n",
    "is considerably higher.\n",
    "This indicates that we are overfitting.\n",
    "Throughout training you will want to monitor both numbers.\n",
    "Less overfitting might indicate that our data can support a more powerful model.\n",
    "Massive overfitting might suggest that we can gain\n",
    "by incorporating regularization techniques.\n",
    "\n",
    "##  [**Submitting Predictions on Kaggle**]\n",
    "\n",
    "Now that we know what a good choice of hyperparameters should be,\n",
    "we might \n",
    "calculate the average predictions \n",
    "on the test set\n",
    "by all the $K$ models.\n",
    "Saving the predictions in a csv file\n",
    "will simplify uploading the results to Kaggle.\n",
    "The following code will generate a file called `submission.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c034ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T05:44:57.545624Z",
     "iopub.status.busy": "2022-12-14T05:44:57.544795Z",
     "iopub.status.idle": "2022-12-14T05:44:57.562639Z",
     "shell.execute_reply": "2022-12-14T05:44:57.561696Z"
    },
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "preds = [model(torch.tensor(data.val.values, dtype=torch.float32))\n",
    "         for model in models]\n",
    "# Taking exponentiation of predictions in the logarithm scale\n",
    "ensemble_preds = torch.exp(torch.cat(preds, 1)).mean(1)\n",
    "submission = pd.DataFrame({'Id':data.raw_val.Id,\n",
    "                           'SalePrice':ensemble_preds.detach().numpy()})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb7429",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "Next, as demonstrated in :numref:`fig_kaggle_submit2`,\n",
    "we can submit our predictions on Kaggle\n",
    "and see how they compare with the actual house prices (labels)\n",
    "on the test set.\n",
    "The steps are quite simple:\n",
    "\n",
    "* Log in to the Kaggle website and visit the house price prediction competition page.\n",
    "* Click the Submit Predictions or Late Submission button (as of this writing, the button is located on the right).\n",
    "* Click the Upload Submission File button in the dashed box at the bottom of the page and select the prediction file you wish to upload.\n",
    "* Click the Make Submission button at the bottom of the page to view your results.\n",
    "\n",
    "![Submitting data to Kaggle](../img/kaggle-submit2.png)\n",
    ":width:`400px`\n",
    ":label:`fig_kaggle_submit2`\n",
    "\n",
    "## Summary\n",
    "\n",
    "Real data often contains a mix of different data types and needs to be preprocessed.\n",
    "Rescaling real-valued data to zero mean and unit variance is a good default. So is replacing missing values with their mean.\n",
    "Besides, transforming categorical features into indicator features allows us to treat them like one-hot vectors.\n",
    "When we tend to care more about\n",
    "the relative error than about the absolute error,\n",
    "we can \n",
    "measure the discrepancy in the logarithm of the prediction.\n",
    "To select the model and adjust the hyperparameters,\n",
    "we can use $K$-fold cross-validation .\n",
    "\n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Submit your predictions for this section to Kaggle. How good are your predictions?\n",
    "1. Is it always a good idea to replace missing values by their mean? Hint: can you construct a situation where the values are not missing at random?\n",
    "1. Improve the score on Kaggle by tuning the hyperparameters through $K$-fold cross-validation.\n",
    "1. Improve the score by improving the model (e.g., layers, weight decay, and dropout).\n",
    "1. What happens if we do not standardize the continuous numerical features like what we have done in this section?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295ee77",
   "metadata": {
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/107)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
